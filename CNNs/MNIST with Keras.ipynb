{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Dense, Flatten\n",
    "from keras import backend\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer as lbin\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters and input shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = SGD(learning_rate)\n",
    "batch_size = 32\n",
    "w, h = X_train[0].shape\n",
    "d = 1\n",
    "classes = 10\n",
    "epochs = 15\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], w, h, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], w, h, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch_size, h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = lbin().fit_transform(y_train)\n",
    "y_test = lbin().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set shape of the input layer\n",
    "model = Sequential()\n",
    "input_layer_shape = (h,w,1)\n",
    "\n",
    "model.add(Conv2D(32,3, padding=\"same\", input_shape=(input_layer_shape), activation='relu'))\n",
    "model.add(Conv2D(64,3, padding=\"same\",activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Set activation function of the CONV layer\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Add softmax classifier to set predictions in range [0,1]\n",
    "model.add(Dense(classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 1.4706 - acc: 0.6805 - val_loss: 0.4667 - val_acc: 0.8746\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.4040 - acc: 0.8842 - val_loss: 0.3371 - val_acc: 0.9038\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.3459 - acc: 0.8990 - val_loss: 0.3108 - val_acc: 0.9116\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.3245 - acc: 0.9059 - val_loss: 0.3043 - val_acc: 0.9142\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.3117 - acc: 0.9093 - val_loss: 0.2861 - val_acc: 0.9176\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.3007 - acc: 0.9133 - val_loss: 0.2764 - val_acc: 0.9203\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.2919 - acc: 0.9155 - val_loss: 0.2713 - val_acc: 0.9224\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.2835 - acc: 0.9186 - val_loss: 0.2616 - val_acc: 0.9242\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.2754 - acc: 0.9205 - val_loss: 0.2593 - val_acc: 0.9258\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.2674 - acc: 0.9230 - val_loss: 0.2532 - val_acc: 0.9268\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.2585 - acc: 0.9260 - val_loss: 0.2422 - val_acc: 0.9315\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.2499 - acc: 0.9279 - val_loss: 0.2351 - val_acc: 0.9315\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.2416 - acc: 0.9303 - val_loss: 0.2279 - val_acc: 0.9343\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.2319 - acc: 0.9331 - val_loss: 0.2148 - val_acc: 0.9367\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.2220 - acc: 0.9369 - val_loss: 0.2105 - val_acc: 0.9400\n"
     ]
    }
   ],
   "source": [
    "tr = model.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size=batch_size, epochs=epochs, verbose = verbose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
